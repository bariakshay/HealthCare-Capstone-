{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Project 2/Healthcare - Diabetes/health care diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from Descriptive Analysis\n",
    "\n",
    "There is 768 observations of 9 variable. Independent variables are Pregnencies , Glucose, BloodPressure, Insulin, BMI and DiabetesPedigree Function. Age is Outcome Variable. Average Age of Patients are 33.24 with minimum being 21 and maximum 81. Avg. value of independent variables are Preg = 3.845052,Glucose = 120.894531, BP = 69.105469, ST=20.536458, Insulin = 79.799479, BMI = 31.992578 DPF = 0.471876 . Variation in variables can be easily observed from table below :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Deviation of each variables are ==> \")\n",
    "data.apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"Glucose Patient\")\n",
    "data['Glucose'].plot.hist()\n",
    "sns.set_style(style='darkgrid')\n",
    "print(\"Mean of Glucose level is :-\", data['Glucose'].mean())\n",
    "print(\"Datatype of Glucose Variable is:\",data['Glucose'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Glucose']=data['Glucose'].replace(0,data['Glucose'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"BloodPressure\")\n",
    "data[\"BloodPressure\"].plot.hist()\n",
    "sns.set_style(style='darkgrid')\n",
    "print(\"Mean of Glucose level is :-\", data['BloodPressure'].mean())\n",
    "print(\"Datatype of Glucose Variable is:\",data['BloodPressure'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BloodPressure']=data['BloodPressure'].replace(0,data['BloodPressure'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"SkinThickness\")\n",
    "data[\"SkinThickness\"].plot.hist()\n",
    "sns.set_style(style='darkgrid')\n",
    "print(\"Mean of Glucose level is :-\", data['SkinThickness'].mean())\n",
    "print(\"Datatype of Glucose Variable is:\",data['SkinThickness'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SkinThickness']=data['SkinThickness'].replace(0,data['SkinThickness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"Insulin\")\n",
    "data[\"Insulin\"].plot.hist()\n",
    "sns.set_style(style='darkgrid')\n",
    "print(\"Mean of Glucose level is :-\", data['Insulin'].mean())\n",
    "print(\"Datatype of Glucose Variable is:\",data['Insulin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Insulin']=data['Insulin'].replace(0,data['Insulin'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"BMI\")\n",
    "data[\"BMI\"].plot.hist()\n",
    "sns.set_style(style='darkgrid')\n",
    "print(\"Mean of Glucose level is :-\", data['BMI'].mean())\n",
    "print(\"Datatype of Glucose Variable is:\",data['BMI'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BMI']=data['BMI'].replace(0,data['BMI'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:- All zeros values are replace with mean of this Variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(data['Outcome'])\n",
    "plt.title(\"Countplot of Outcome\")\n",
    "plt.xlabel('Outcome')\n",
    "plt.ylabel(\"Count\")\n",
    "print(\"Count of class is:\\n\",data['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:- Here we can see that both the outcome i.e 0 & 1 is seen to be Balanced. So we can used this data to for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data,hue=\"Outcome\")\n",
    "plt.title('Scatter Plot Between Variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:- We can see from scatter plot that there is no strong multicolinearity among features, but between skin thickness and BMI, Pregnancies and age it looks like there is small chance of positive correlation..i will explore more when analyzing correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:- Glucose and BMI has strong impact on the Outcome. There is a strong positive correlation between BMI and Skinthickness or Pregnancies and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "sns.heatmap(data.corr(),cmap='PiYG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('Outcome',axis=1)\n",
    "y=data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let Standarized Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale=StandardScaler()\n",
    "xtrain_scale=scale.fit_transform(xtrain)\n",
    "xtest_scale=scale.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let also Normalize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=lambda a:((a-min(a))/(max(a)-min(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm=data.drop('Outcome',axis=1)\n",
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm=X_norm.apply(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_norm,xtest_norm,ytrain_norm,ytest_norm=train_test_split(data_norm.values,y,test_size=0.20,random_state=0)\n",
    "print(xtrain_norm.shape)\n",
    "print(xtest_norm.shape)\n",
    "print(ytrain_norm.shape)\n",
    "print(ytest_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN CLassification using standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model=KNeighborsClassifier()\n",
    "knn_model.fit(xtrain_scale,ytrain)\n",
    "ypredict=knn_model.predict(xtest_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Model Validation\")\n",
    "print('Acuuracy Score of Knn Model is')\n",
    "print(metrics.accuracy_score(ytest,ypredict))\n",
    "print(\"Classification Report is \")\n",
    "print(metrics.classification_report(ytest,ypredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC Curve----\")\n",
    "ypred_prob=knn_model.predict_proba(xtest_scale)\n",
    "ypred_prob1=ypred_prob[:,1]\n",
    "fpr,tpr,thresh=metrics.roc_curve(ytest,ypred_prob1)\n",
    "roc_auc_curve=metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(fpr,tpr,'b',label='AUC Score=%0.2f'%roc_auc_curve)\n",
    "plt.plot(fpr,fpr,'r--',color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classification using Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_norm=KNeighborsClassifier()\n",
    "knn_model_norm.fit(xtrain_norm,ytrain)\n",
    "yprdict_norm=knn_model_norm.predict(xtest_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Model Validation\")\n",
    "print('Acuuracy Score of Knn Model is')\n",
    "print(metrics.accuracy_score(ytest,yprdict_norm))\n",
    "print(\"Classification Report is \")\n",
    "print(metrics.classification_report(ytest,yprdict_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC Curve of Normalize data-->\")\n",
    "yprob_nom=knn_model_norm.predict_proba(xtest_norm)\n",
    "yprob_nom1=yprob_nom[:,1]\n",
    "fpr1,tpr1,thresh1=metrics.roc_curve(ytest,yprob_nom1)\n",
    "roc_auc_curve2=metrics.auc(fpr1,tpr1)\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(fpr1,tpr1,'b',label='AUC Score=%0.2f'%roc_auc_curve2)\n",
    "plt.plot(fpr1,fpr1,'r--',color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:- From above ROC curve and Accuracy score its clear that module using Standard scaling method is good fit module.Because this module has better AUC score. So we used Standard Scaling method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(xtrain_scale,ytrain)\n",
    "ypredict=lr.predict(xtest_scale)\n",
    "ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score of Logistic Regression module-->\")\n",
    "print(metrics.accuracy_score(ytest,ypredict))\n",
    "print(\"Confusion Metric -\")\n",
    "print(metrics.confusion_matrix(ytest,ypredict))\n",
    "print(\"Classification Report -\")\n",
    "print(metrics.classification_report(ytest,ypredict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Roc Curve of logistics==>')\n",
    "lrprob=lr.predict_proba(xtest_scale)\n",
    "lrprob1=lrprob[:,1]\n",
    "tpr,fpr,thrash=metrics.roc_curve(ytest,lrprob1)\n",
    "auc_score=metrics.auc(tpr,fpr)\n",
    "plt.figure(figsize=(8,6),dpi=80)\n",
    "plt.title(\"ROC CURVE\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(tpr,fpr,'b',label='AUC Score=%0.2f'%auc_score)\n",
    "plt.plot(tpr,tpr,'r--',color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:- As compare KNN module, Logistic Regression look better module because it has better accuracy score=81% and AUC Score=88% of Logistic Regression module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv1=SVC(kernel='linear',random_state=0,probability=True,C=0.01)\n",
    "sv1.fit(xtrain_scale,ytrain)\n",
    "svc_predict=sv1.predict(xtest_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score of SVM==>\")\n",
    "print(metrics.accuracy_score(ytest,svc_predict))\n",
    "print(\"Confusion Metrics==>\")\n",
    "print(metrics.confusion_matrix(ytest,svc_predict))\n",
    "print(\"Classification Report -\")\n",
    "print(metrics.classification_report(ytest,svc_predict))\n",
    "print(\"ROC Curve\")\n",
    "svc_prob=sv1.predict_proba(xtest_scale)\n",
    "svc_prob1=svc_prob[:,1]\n",
    "fpr,tpr,thresh=metrics.roc_curve(ytest,svc_prob1)\n",
    "auc_score=metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8,6),dpi=80)\n",
    "plt.title(\"ROC CURVE of SVM\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(fpr,tpr,'b',label='AUC Score=%0.2f'%auc_score)\n",
    "plt.plot(fpr,fpr,'r--',color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=1000,random_state=0)\n",
    "rf_model.fit(xtrain_scale,ytrain)\n",
    "rf_pred=rf_model.predict(xtest_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score of Random Forest Classifier==>\")\n",
    "print(metrics.accuracy_score(ytest,rf_pred))\n",
    "print(\"Confusion Metrics==>\")\n",
    "print(metrics.confusion_matrix(ytest,rf_pred))\n",
    "print(\"Classification Report -\")\n",
    "print(metrics.classification_report(ytest,rf_pred))\n",
    "print(\"ROC Curve\")\n",
    "\n",
    "rf_prob=rf_model.predict_proba(xtest_scale)\n",
    "rf_prob1=rf_prob[:,1]\n",
    "fpr,tpr,thresh=metrics.roc_curve(ytest,rf_prob1)\n",
    "auc_score=metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8,6),dpi=80)\n",
    "plt.title(\"ROC CURVE of SVM\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot(fpr,tpr,'b',label='AUC Score=%0.2f'%auc_score)\n",
    "plt.plot(fpr,fpr,'r--',color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:- The Random Forest module look better because it has better accuracy score=83% and AUC Score=87% of Forest module Classifier module as compare to KNN module,Logistic Regression & Support vector machine. It has better balanced of classes between precision,recall,f1-score as compared to other model. So we choose Random Forest Classifier best fit module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a20352473a05325d20270c0969f5ea8b136bc29190aab5a4ace3c70d2158a7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
